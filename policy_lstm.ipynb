{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c324db66859e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPolicyLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_training_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# -------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\variables.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddons\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_arg_scope\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcontrib_add_arg_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.addons'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflearn\n",
    "\n",
    "class PolicyLSTM(object):\n",
    "    '''\n",
    "    Using this class we will build policy for the LSTM network.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ohlc_feature_num, ticker_num, num_trading_periods, sess, optimizer, trading_cost, cash_bias_init, interest_rate, equiweight_vector, adjusted_rewards_alpha, num_filter_layer):\n",
    "\n",
    "        # parameters\n",
    "        self.ohlc_feature_num = ohlc_feature_num\n",
    "        self.ticker_num = ticker_num\n",
    "        self.num_trading_periods =  num_trading_periods\n",
    "        self.trading_cost = trading_cost\n",
    "        self.cash_bias_init = cash_bias_init\n",
    "        self.interest_rate = interest_rate\n",
    "        self.equiweight_vector = equiweight_vector\n",
    "        self.adjusted_rewards_alpha = adjusted_rewards_alpha \n",
    "        self.optimizer = optimizer\n",
    "        self.sess = sess\n",
    "        self.num_filter_layer = num_filter_layer\n",
    "        layers=2\n",
    "        lstm_neurons = 20\n",
    "\n",
    "        self.X_t = tf.placeholder(tf.float32, [None, self.ohlc_feature_num, self.ticker_num, self.num_trading_periods])\n",
    "        self.weights_previous_t = tf.placeholder(tf.float32, [None, self.ticker_num + 1])\n",
    "        self.pf_previous_t = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.daily_returns_t = tf.placeholder(tf.float32, [None, self.ticker_num]) \n",
    "        cash_bias = tf.get_variable('cash_bias', shape=[1, 1, 1, 1], initializer = tf.constant_initializer(self.cash_bias_init))\n",
    "        shape_X_t = tf.shape(self.X_t)[0]\n",
    "        self.cash_bias = tf.tile(cash_bias, tf.stack([shape_X_t, 1, 1, 1]))\n",
    "\n",
    "\n",
    "        def lstm(X_t):\n",
    "            network = tf.transpose(X_t, [0, 1, 3, 2])\n",
    "            network = network / network[:, :, -1, 0, None, None]\n",
    "\n",
    "            for layer_number in range(layers):\n",
    "                resultlist = []\n",
    "                reuse = False\n",
    "\n",
    "                for i in range(self.ticker_num):\n",
    "                    if i > 0:\n",
    "                        reuse = True\n",
    "\n",
    "                    result = tflearn.layers.lstm(X_t[:,:,:, i],\n",
    "                                                    lstm_neurons,\n",
    "                                                    dropout=0.3,\n",
    "                                                    scope=\"lstm\"+str(layer_number),\n",
    "                                                    reuse=reuse)\n",
    "            \n",
    "\n",
    "                    resultlist.append(result)\n",
    "                network = tf.stack(resultlist)\n",
    "                network = tf.transpose(network, [1, 0, 2])\n",
    "                network = tf.reshape(network, [-1, 1, self.ticker_num, lstm_neurons])\n",
    "                # print('dhsegfhebgfhewf', network.shape)\n",
    "            return network\n",
    "\n",
    "        def policy_output(network, cash_bias):\n",
    "            with tf.variable_scope(\"Convolution_Layer\"):\n",
    "                self.conv = tf.layers.conv2d(\n",
    "                    inputs = network,\n",
    "                    activation = tf.nn.relu,\n",
    "                    filters = 1,\n",
    "                    strides = (num_filter_layer + 1, 1),\n",
    "                    kernel_size = (1, 1),\n",
    "                    padding = 'same')\n",
    "\n",
    "            with tf.variable_scope(\"Policy-Output\"):\n",
    "                tensor_squeeze = tf.squeeze(tf.concat([cash_bias, self.conv], axis=2), [1,3])\n",
    "                self.action = tf.nn.softmax(tensor_squeeze)\n",
    "            return self.action\n",
    "\n",
    "\n",
    "        def reward(shape_X_t, action_chosen, interest_rate, weights_previous_t, pf_previous_t, daily_returns_t, trading_cost):\n",
    "            #Calculating reward for current Portfolio\n",
    "            with tf.variable_scope(\"Reward\"):\n",
    "                cash_return = tf.tile(tf.constant(1 + interest_rate, shape=[1, 1]), tf.stack([shape_X_t, 1]))\n",
    "                y_t = tf.concat([cash_return, daily_returns_t], axis=1)\n",
    "                pf_vector_t = action_chosen * pf_previous_t\n",
    "                pf_vector_previous = weights_previous_t * pf_previous_t\n",
    "\n",
    "                total_trading_cost = trading_cost * tf.norm(pf_vector_t - pf_vector_previous, ord=1, axis=1) * tf.constant(1.0, shape=[1])\n",
    "                total_trading_cost = tf.expand_dims(total_trading_cost, 1)\n",
    "\n",
    "                zero_vector = tf.tile(tf.constant(np.array([0.0] * ticker_num).reshape(1, ticker_num), shape=[1, ticker_num], dtype=tf.float32), tf.stack([shape_X_t, 1]))\n",
    "                cost_vector = tf.concat([total_trading_cost, zero_vector], axis=1)\n",
    "\n",
    "                pf_vector_second_t = pf_vector_t - cost_vector\n",
    "                final_pf_vector_t = tf.multiply(pf_vector_second_t, y_t)\n",
    "                portfolio_value = tf.norm(final_pf_vector_t, ord=1)\n",
    "                self.instantaneous_reward = (portfolio_value - pf_previous_t) / pf_previous_t\n",
    "                \n",
    "            #Calculating Reward for Equiweight portfolio\n",
    "            with tf.variable_scope(\"Reward-Equiweighted\"):\n",
    "                cash_return = tf.tile(tf.constant(1 + interest_rate, shape=[1, 1]), tf.stack([shape_X_t, 1]))\n",
    "                y_t = tf.concat([cash_return, daily_returns_t], axis=1)\n",
    "  \n",
    "                pf_vector_eq = self.equiweight_vector * pf_previous_t\n",
    "        \n",
    "                portfolio_value_eq = tf.norm(tf.multiply(pf_vector_eq, y_t), ord=1)\n",
    "                self.instantaneous_reward_eq = (portfolio_value_eq - pf_previous_t) / pf_previous_t\n",
    "\n",
    "            #Calculating Adjusted Rewards\n",
    "            with tf.variable_scope(\"Reward-adjusted\"):\n",
    "                self.adjusted_reward = self.instantaneous_reward - self.instantaneous_reward_eq - self.adjusted_rewards_alpha * tf.reduce_max(action_chosen)\n",
    "                \n",
    "            return self.adjusted_reward\n",
    "\n",
    "\n",
    "        self.lstm_layer = lstm(self.X_t)\n",
    "        self.action_chosen = policy_output(self.lstm_layer, self.cash_bias)\n",
    "        self.adjusted_reward = reward(shape_X_t, self.action_chosen, self.interest_rate, self.weights_previous_t, self.pf_previous_t, self.daily_returns_t, self.trading_cost)\n",
    "        self.train_op = optimizer.minimize(-self.adjusted_reward)\n",
    "\n",
    "    def compute_weights(self, X_t_, weights_previous_t_):\n",
    "        # tf.print(self.action_chosen)\n",
    "        return self.sess.run(tf.squeeze(self.action_chosen), feed_dict={self.X_t: X_t_, self.weights_previous_t: weights_previous_t_})\n",
    "\n",
    "    def train_lstm(self, X_t_, weights_previous_t_, pf_previous_t_, daily_returns_t_):\n",
    "        \"\"\"\n",
    "        training the neural network\n",
    "        \"\"\"\n",
    "        self.sess.run(self.train_op, feed_dict={self.X_t: X_t_,\n",
    "                                                self.weights_previous_t: weights_previous_t_,\n",
    "                                                self.pf_previous_t: pf_previous_t_,\n",
    "                                                self.daily_returns_t: daily_returns_t_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
